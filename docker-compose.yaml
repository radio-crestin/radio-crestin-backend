services:
  postgres:
    image: timescale/timescaledb-ha:pg16
    restart: unless-stopped
    shm_size: 2gb
    volumes:
      - db_data:/home/postgres/pgdata/data
    env_file:
      - .env
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "postgres", "-U", "postgres" ]
      timeout: 45s
      interval: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-file: "5"   # number of files or file count
        max-size: "100m" # file size
  redis:
    image: redis:7.2-alpine
    restart: unless-stopped
    ports:
      - "6379:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    volumes:
      - redis:/data
    command: redis-server --requirepass ${REDIS_PASSWORD} --notify-keyspace-events Exe
  web:
    build:
      context: backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - "postgres"
    ports:
      - "8080:8080"
    volumes:
      - ./backend:/app:delegated
      - /app/__pycache__
      - /app/**/__pycache__
    env_file:
      - .env
    stdin_open: true
    tty: true
    command: /app/scripts/run-server.sh
  priority-worker:
    build:
      context: backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - "postgres"
      - "redis"
    volumes:
      - ./backend:/app:delegated
      - /app/__pycache__
      - /app/**/__pycache__
    env_file:
      - .env
    command: /app/scripts/run-priority-worker.sh
    healthcheck:
      test: ["CMD", "ps", "aux", "|", "grep", "[c]elery -A superapp worker"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"
  worker:
    build:
      context: backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - "postgres"
      - "redis"
    volumes:
      - ./backend:/app:delegated
      - /app/__pycache__
      - /app/**/__pycache__
    env_file:
      - .env
    command: /app/scripts/run-worker.sh
    healthcheck:
      test: ["CMD", "ps", "aux", "|", "grep", "[c]elery -A superapp worker"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"
  graphql-engine:
    image: hasura/graphql-engine:v2.33.4.cli-migrations-v3
    ports:
      - "8081:8080"
    depends_on:
      - "postgres"
    restart: unless-stopped
    env_file:
      - .env
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
  backend-hls-streaming:
    build:
      context: backend_hls_streaming
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - "web"
      - "postgres"
      - "redis"
    ports:
      - "8082:80"  # NGINX HLS serving port
    volumes:
      # Mount backend_hls_streaming directory for development
      - ./backend_hls_streaming:/app:delegated
    environment:
      # HLS Manager configuration
      - GRAPHQL_ENDPOINT=http://web:8080/graphql
      - GRAPHQL_TOKEN=${HLS_GRAPHQL_TOKEN:-}
      - ADMIN_GRAPHQL_SUPERUSER_API_KEY=${ADMIN_GRAPHQL_SUPERUSER_API_KEY}
      - STREAM_REFRESH_INTERVAL=60
      - LOG_LEVEL=DEBUG
      - MAX_LOG_SIZE_MB=20
      # Log Monitor configuration
      - NGINX_LOG_PATH=/tmp/nginx_session_access.log
      - BATCH_INTERVAL_SECONDS=10
      - SESSION_TIMEOUT_MINUTES=5
      # Enhanced Logging Configuration
      - DETAILED_LOGGING=true
      - VERBOSE_LOGGING=false
      - LOG_PROCESSES=true
      - LOG_FFMPEG=true
      - LOG_NGINX=true
      - LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
    healthcheck:
      test: ["CMD", "python3", "scripts/health_check.py"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"

volumes:
  db_data:
  redis:
