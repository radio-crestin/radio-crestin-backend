services:
  postgres:
    image: timescale/timescaledb-ha:pg16
    restart: unless-stopped
    shm_size: 2gb
    volumes:
      - db_data:/home/postgres/pgdata/data
    env_file:
      - .env
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "postgres", "-U", "postgres" ]
      timeout: 45s
      interval: 10s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-file: "5"   # number of files or file count
        max-size: "100m" # file size
  redis:
    image: redis:7.2-alpine
    restart: unless-stopped
    ports:
      - "6379:6379"
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    volumes:
      - redis:/data
    command: redis-server --requirepass ${REDIS_PASSWORD} --notify-keyspace-events Exe
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"
  web:
    build:
      context: backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8080:8080"
    volumes:
      - ./backend:/app:delegated
      - /app/__pycache__
      - /app/**/__pycache__
    env_file:
      - .env
    stdin_open: true
    tty: true
    command: /app/scripts/run-server.sh
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"
  priority-worker:
    build:
      context: backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app:delegated
      - /app/__pycache__
      - /app/**/__pycache__
    env_file:
      - .env
    command: /app/scripts/run-priority-worker.sh
    healthcheck:
      test: ["CMD-SHELL", "celery -A superapp inspect ping --destination celery@$$HOSTNAME 2>/dev/null | grep -q OK || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"
  worker:
    build:
      context: backend
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app:delegated
      - /app/__pycache__
      - /app/**/__pycache__
    env_file:
      - .env
    command: /app/scripts/run-worker.sh
    healthcheck:
      test: ["CMD-SHELL", "celery -A superapp inspect ping --destination celery@$$HOSTNAME 2>/dev/null | grep -q OK || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"
  backend-hls-streaming:
    build:
      context: backend_hls_streaming
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      web:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8082:80"  # NGINX HLS serving port
    volumes:
      # Mount backend_hls_streaming directory for development
      - ./backend_hls_streaming:/app:delegated
    environment:
      # HLS Manager configuration
      - GRAPHQL_ENDPOINT=http://web:8080/v1/graphql
      - GRAPHQL_TOKEN=${HLS_GRAPHQL_TOKEN:-}
      - ADMIN_GRAPHQL_SUPERUSER_API_KEY=${ADMIN_GRAPHQL_SUPERUSER_API_KEY}
      - STREAM_REFRESH_INTERVAL=60
      - LOG_LEVEL=DEBUG
      - MAX_LOG_SIZE_MB=20
      # Log Monitor configuration
      - NGINX_LOG_PATH=/tmp/nginx_session_access.log
      - BATCH_INTERVAL_SECONDS=10
      - SESSION_TIMEOUT_MINUTES=5
      # Enhanced Logging Configuration
      - DETAILED_LOGGING=true
      - VERBOSE_LOGGING=false
      - LOG_PROCESSES=true
      - LOG_FFMPEG=true
      - LOG_NGINX=true
      - LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
    healthcheck:
      test: ["CMD", "python3", "scripts/health_check.py"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-file: "5"
        max-size: "100m"

volumes:
  db_data:
  redis:
